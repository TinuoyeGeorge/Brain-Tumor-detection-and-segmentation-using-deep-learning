#This file contains a full python code for detecting and segmenting brain tumor images.
#The file should be downloaded, and ran on visual studio code to view contents.

pip install numpy
pip install tensorflow
pip install keras
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.applications.vgg16 import VGG16
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import tensorflow as tf
from sklearn.metrics import precision_score, recall_score, f1_score
import matplotlib.pyplot as plt
import cv2
import matplotlib.pyplot as plt
upic='/kaggle/input/tinu-new/dataset2/Testing/glioma/Te-glTr_0000.jpg'
apic='/kaggle/input/tinu-new/dataset2/Testing/notumor/Te-noTr_0000.jpg'
plt.figure(1, figsize=(15, 7))
plt.subplot(1, 2, 1)
uninfected_img = cv2.imread(upic)
uninfected_img = cv2.cvtColor(uninfected_img, cv2.COLOR_BGR2RGB) # Convert 
BGR to RGB color space
plt.imshow(uninfected_img)
74
plt.title('Tumor')
plt.xticks([]), plt.yticks([])
plt.subplot(1, 2, 2)
parasitized_img = cv2.imread(apic)
parasitized_img = cv2.cvtColor(parasitized_img, cv2.COLOR_BGR2RGB) # Convert 
BGR to RGB color space
plt.imshow(parasitized_img)
plt.title('No Tumor')
plt.xticks([]), plt.yticks([])
plt.show()
np.random.seed(42)
tf.random.set_seed(42)
input_shape = (224, 224, 3)
batch_size = 32
epochs = 10 # Increase the number of epochs
train_path = '/kaggle/input/tinu-new/dataset2/Training'
val_path = '/kaggle/input/tinu-new/dataset2/Testing'
# Data augmentation with additional transformations
train_datagen = ImageDataGenerator(
 rescale=1./255,
 shear_range=0.2,
 zoom_range=0.2,
 horizontal_flip=True,
 rotation_range=10, # Additional rotation
 width_shift_range=0.1, # Additional width shift
 height_shift_range=0.1, # Additional height shift
75
 brightness_range=[0.8, 1.2], # Additional brightness adjustment
)
val_datagen = ImageDataGenerator(rescale=1./255)
train_generator = train_datagen.flow_from_directory(
 train_path,
 target_size=input_shape[:2],
 batch_size=batch_size,
 class_mode='categorical',
 shuffle=True
)
val_generator = val_datagen.flow_from_directory(
 val_path,
 target_size=input_shape[:2],
 batch_size=batch_size,
 class_mode='categorical',
 shuffle=False
)
from tensorflow.keras.applications.vgg16 import VGG16
vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)
# Fine-tune some of the later layers
for layer in vgg16.layers[:15]:
 layer.trainable = False
x = Flatten()(vgg16.output)
x = Dense(256, activation='relu')(x)
x = Dropout(0.5)(x) # Add dropout for regularization
76
x = Dense(train_generator.num_classes, activation='softmax')(x)
model = Model(inputs=vgg16.input, outputs=x)
model.summary()
optimizer = Adam(learning_rate=0.0001)
model.compile(optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
history = model.fit(train_generator, epochs=epochs, validation_data=val_generator)
model.save('path_to_save_model.h5')
# Evaluate the model on the test set
test_predictions = model.predict(val_generator)
test_predictions = np.argmax(test_predictions, axis=1) # Convert probabilities to class 
labels
val_labels = val_generator.classes
accuracy = accuracy_score(val_labels, test_predictions)
print('Accuracy:', accuracy )
# Plot the learning curve
def plotLearningCurve(history):
 plt.plot(history.history['accuracy'])
 plt.plot(history.history['val_accuracy'])
 plt.title('Model Accuracy')
 plt.xlabel('Epoch')
 plt.ylabel('Accuracy')
 plt.legend(['Train', 'Validation'], loc='upper left')
 plt.show()
 plt.plot(history.history['loss'])
 plt.plot(history.history['val_loss'])
 plt.title('Model Loss')
77
 plt.xlabel('Epoch')
 plt.ylabel('Loss')
 plt.legend(['Train', 'Validation'], loc='upper left')
 plt.show()
from sklearn.metrics import classification_report
report = classification_report(val_labels, test_predictions)
print('Classification Report:')
print(report)
# Plot classification report as a bar graph
labels = ['0', '1'] # Replace with your class labels
precision = [0.98, 0.84] # Replace with precision values
recall = [0.91, 0.97] # Replace with recall values
f1_score = [0.95, 0.90] # Replace with F1 scores
x = range(len(labels))
plt.bar(x, precision, width=0.2, label='Precision')
plt.bar(x, recall, width=0.2, label='Recall')
plt.bar(x, f1_score, width=0.2, label='F1 Score')
plt.xlabel('Class')
plt.ylabel('Score')
plt.title('Classification Report')
plt.xticks(x, labels)
plt.legend()
plt.show()
import cv2
from keras.applications.vgg16 import VGG16
78
from keras.models import Model
from keras.layers import Conv2D, UpSampling2D
# VGG16-based FCN architecture
def fcn_vgg16():
 vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(None, 
None, 3))
 for layer in vgg_model.layers:
 layer.trainable = False
 # Add convolutional layers for upsampling
 x = Conv2D(4096, (7, 7), activation='relu', padding='same')(vgg_model.output)
 x = Conv2D(4096, (1, 1), activation='relu', padding='same')(x)
 x = Conv2D(21, (1, 1), activation='softmax', padding='same')(
 x = UpSampling2D(size=(32, 32))(x)
 # Create the FCN model
 fcn_model = Model(inputs=vgg_model.input, outputs=x)
 return fcn_model
# Load the FCN model
model = fcn_vgg16()
# Perform image segmentation
def segment_image(image):
 image = cv2.resize(image, (224, 224))
 image = image.astype('float32')
 image = np.expand_dims(image, axis=0)
 image = image / 255.0
 mask = model.predict(image)
 mask = np.argmax(mask, axis=3)[0]
79
 return mask
model.save('fcn_model.h5')
import cv2
import matplotlib.pyplot as plt
from keras.applications.vgg16 import VGG16
from keras.models import Model
from keras.layers import Conv2D, UpSampling2
# VGG16-based FCN architecture
def fcn_vgg16():
 vgg_model = VGG16(weights='imagenet', include_top=False, input_shape=(None, 
None, 3))
 for layer in vgg_model.layers:
 layer.trainable = False
 x = Conv2D(4096, (7, 7), activation='relu', padding='same')(vgg_model.output)
 x = Conv2D(4096, (1, 1), activation='relu', padding='same')(x)
 x = Conv2D(21, (1, 1), activation='softmax', padding='same')(x)
 x = Upsampling2D(size=(32, 32))(x)
 # Create the FCN model
 fcn_model = Model(inputs=vgg_model.input, outputs=x)
 return fcn_model
model = fcn_vgg16()
# Perform image segmentation
def segment_image(image):
 image = cv2.resize(image, (224, 224))
 image = image.astype('float32')
 image = np.expand_dims(image, axis=0)
80
 image = image / 255.0
 # Perform segmentation
 mask = model.predict(image)
 mask = np.argmax(mask, axis=3)[0]
 return mask
image_paths = ['/kaggle/input/tinu-new/dataset2/Testing/glioma/Te-glTr_0001.jpg', 
'/kaggle/input/tinu-new/dataset2/Testing/meningioma/Te-meTr_0001.jpg', 
'/kaggle/input/tinu-new/dataset2/Testing/notumor/Te-noTr_0001.jpg']
# Perform segmentation on sample images
for image_path in image_paths:
 image = cv2.imread(image_path)
 mask = segment_image(image)
 # Display the segmentation mask
 plt.imshow(mask)
 plt.title('Segmentation Mask')
 plt.show()
import cv2
import numpy as np
import matplotlib.pyplot as plt
def segment_image(image):
 gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
 _, binary_mask = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
 kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))
 closed_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_CLOSE, kernel)
 return closed_mask
# Function to check size, location, and shape of segmented image
81
def check_segmentation_properties(mask):
 # Compute the size of the segmented image
 size = mask.size
 # Compute the location of the segmented image
 location = np.nonzero(mask)
 # Compute the shape of the segmented image
 shape = mask.shape
 return size, location, shape
image_paths =['/kaggle/input/tinu-new/dataset2/Testing/glioma/Te-glTr_0001.jpg',
 '/kaggle/input/tinu-new/dataset2/Testing/meningioma/Te-meTr_0001.jpg',
 '/kaggle/input/tinu-new/dataset2/Testing/notumor/Te-noTr_0001.jpg']
# Perform segmentation and check properties on sample images
for image_path in image_paths:
 image = cv2.imread(image_path)
 mask = segment_image(image)
 # Check segmentation properties
 size, location, shape = check_segmentation_properties(mask)
 print(f"Segmentation Properties - Size: {size}, Location: {location}, Shape: 
{shape}")
 plt.imshow(mask, cmap='gray')
 plt.title('Segmentation Mask')
 plt.show()
from sklearn.metrics import classification_report
import random
model = tf.keras.models.load_model('path_to_save_model.h5')
def preprocess_image(image):
82
 resized_image = cv2.resize(image, (224, 224))
 resized_image = resized_image.astype(np.float32)
 normalized_image = resized_image / 255.0
 return normalized_image
 def classify_image(image):
 preprocessed_image = preprocess_image(image)
 predictions = model.predict(np.expand_dims(preprocessed_image, axis=0))
 predicted_label = np.argmax(predictions)
 return predicted_label
# Define the tumor type labels
tumor_labels = {
 0: 'glioma',
 1: 'meningioma',
 2: 'notumor',
 3: 'pituitary',
 4: 'unknown'
}
image_dir = '/kaggle/input/tinu-new/dataset2/Testing/'
image_paths = []
for root, dirs, files in os.walk(image_dir):
 for file in files:
 image_path = os.path.join(root, file)
 image_paths.append(image_path)
# Randomly select 5 image paths
random.shuffle(image_paths)
83
image_paths = image_paths[:15]
true_labels = []
predicted_labels = []
for image_path in image_paths:
 image = cv2.imread(image_path)
 predicted_label = classify_image(image)
 label = os.path.basename(os.path.dirname(image_path))
 true_label = list(tumor_labels.keys())[list(tumor_labels.values()).index(label)
 true_labels.append(true_label)
 predicted_labels.append(predicted_label)
 # Display the results
 predicted_tumor = tumor_labels.get(predicted_label, 'unknown')
 print(f"Image: {os.path.basename(image_path)}, True Class: {label}, Predicted 
Class: {predicted_tumor}")
 plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))
 plt.axis('off')
 plt.show()
# Calculate classification metrics
report = classification_report(true_labels, predicted_labels, 
labels=list(tumor_labels.keys()), target_names=list(tumor_labels.values()))
print("Classification Report:")
print(report)
from sklearn.metrics import accuracy_score
accuracy = accuracy_score(true_labels, predicted_labels)
print("Accuracy:", accuracy
